{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "ISB_RNN.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLPR60ovMgOq"
      },
      "source": [
        "### Practical Session on Recurrent Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMG1ijy9MgO3"
      },
      "source": [
        "#### This session demonstrates the application of RNNs using sentiment classification on TripAdvisor reviews. Long Short Term Memory (LSTM) network is used to model sequential text data found in reviews and to develop a Binary Classification model which learns to predict review sentiment as positive or negative."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pde9t2fBWr1X"
      },
      "source": [
        "# ! pip install --user -r requirements.txt\n",
        "from IPython import get_ipython\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "ipython = get_ipython()\n",
        "ipython.magic(\"sx wget https://www.dropbox.com/s/80yl6pxjx7usk4p/ISB_PyTorch_Tutorial.zip\") \n",
        "!unzip -q ISB_PyTorch_Tutorial.zip\n",
        "!mv ISB_PyTorch_Tutorial/* ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "O7IXwgJmMgO5"
      },
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "torch.manual_seed(0)\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.use_deterministic_algorithms(True)\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import os\n",
        "import re\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix\n",
        "\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO7z1ZGgMgPN"
      },
      "source": [
        "\"\"\"Params for training & evaluation\n",
        "dataFileName: TAB separated file having reviews and ratings\n",
        "embeddingDim: Size of Word embeddings. We'll use pretrained FastText Word Embeddings - https://github.com/facebookresearch/MUSE\n",
        "\"\"\"\n",
        "dataFileName = \"TripAdvisor_Hotel_Restaurant_Review_Samples.txt\"\n",
        "embeddingDim = 300                                               "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhyKmdaHMgPN"
      },
      "source": [
        "#### Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "jQWhpfMDMgPO",
        "outputId": "c0c08028-2aac-478c-de50-4b7396eb6676"
      },
      "source": [
        "\"\"\"\n",
        "Read the data into a pandas DataFrame. Only the second and third columns are required.\n",
        "The second column is review text and third one is review rating on a scale of 0-10.\n",
        "\"\"\"\n",
        "df = pd.read_csv(dataFileName, sep=\"\\t\", header=None, usecols=[0,1], names=[\"Rating\", \"Review\"], encoding=\"utf8\")\n",
        "print(\"No. of reviews:\", df.shape[0])\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of reviews: 100000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10.0</td>\n",
              "      <td>A dream cottage in a dream village. A very per...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10.0</td>\n",
              "      <td>Always stay here when in Brighton and wouldn't...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10.0</td>\n",
              "      <td>A warm welcome awaits at this secluded B+B. Br...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.0</td>\n",
              "      <td>Ann and David are perfect hosts and a stay in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10.0</td>\n",
              "      <td>A very comfortable B&amp;B located a short walk ou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10.0</td>\n",
              "      <td>Comfortable, cosy, clean accommodation. Warm w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>8.0</td>\n",
              "      <td>I stayed here as part of a large group of girl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10.0</td>\n",
              "      <td>I have just returned from a Stag Weekend with ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10.0</td>\n",
              "      <td>4th time we have stayed here. Ther were 9 of u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10.0</td>\n",
              "      <td>12 of us just stayed here on my hen weekend 21...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Rating                                             Review\n",
              "0    10.0  A dream cottage in a dream village. A very per...\n",
              "1    10.0  Always stay here when in Brighton and wouldn't...\n",
              "2    10.0  A warm welcome awaits at this secluded B+B. Br...\n",
              "3    10.0  Ann and David are perfect hosts and a stay in ...\n",
              "4    10.0  A very comfortable B&B located a short walk ou...\n",
              "5    10.0  Comfortable, cosy, clean accommodation. Warm w...\n",
              "6     8.0  I stayed here as part of a large group of girl...\n",
              "7    10.0  I have just returned from a Stag Weekend with ...\n",
              "8    10.0  4th time we have stayed here. Ther were 9 of u...\n",
              "9    10.0  12 of us just stayed here on my hen weekend 21..."
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "LI-OaKYtMgPQ",
        "outputId": "a2097be7-a289-415c-d7f8-461910d680a1"
      },
      "source": [
        "\"\"\"\n",
        "Let's take a quick look at the distribution of different ratings\n",
        "\"\"\"\n",
        "rating_frequency_count = df.Rating.value_counts()\n",
        "sns.barplot(x=rating_frequency_count.index, y=rating_frequency_count.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8089237a10>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Ps838pswMgPR",
        "outputId": "6e02e4c2-b802-4484-bb85-18391357edcc"
      },
      "source": [
        "\"\"\"\n",
        "Add \"Sentiment\" column to the DataFrame based on the rule: IF Rating <= 5 THEN Negative ELSE Positive.\n",
        "Later, we will use the Review and Sentiment columns to train a Binary Classifier\n",
        "\"\"\"\n",
        "df[\"Sentiment\"] = df[\"Rating\"].map(lambda x: \"Negative\" if x <= 5 else \"Positive\")\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating</th>\n",
              "      <th>Review</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10.0</td>\n",
              "      <td>A dream cottage in a dream village. A very per...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10.0</td>\n",
              "      <td>Always stay here when in Brighton and wouldn't...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10.0</td>\n",
              "      <td>A warm welcome awaits at this secluded B+B. Br...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.0</td>\n",
              "      <td>Ann and David are perfect hosts and a stay in ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10.0</td>\n",
              "      <td>A very comfortable B&amp;B located a short walk ou...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10.0</td>\n",
              "      <td>Comfortable, cosy, clean accommodation. Warm w...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>8.0</td>\n",
              "      <td>I stayed here as part of a large group of girl...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10.0</td>\n",
              "      <td>I have just returned from a Stag Weekend with ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10.0</td>\n",
              "      <td>4th time we have stayed here. Ther were 9 of u...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10.0</td>\n",
              "      <td>12 of us just stayed here on my hen weekend 21...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Rating                                             Review Sentiment\n",
              "0    10.0  A dream cottage in a dream village. A very per...  Positive\n",
              "1    10.0  Always stay here when in Brighton and wouldn't...  Positive\n",
              "2    10.0  A warm welcome awaits at this secluded B+B. Br...  Positive\n",
              "3    10.0  Ann and David are perfect hosts and a stay in ...  Positive\n",
              "4    10.0  A very comfortable B&B located a short walk ou...  Positive\n",
              "5    10.0  Comfortable, cosy, clean accommodation. Warm w...  Positive\n",
              "6     8.0  I stayed here as part of a large group of girl...  Positive\n",
              "7    10.0  I have just returned from a Stag Weekend with ...  Positive\n",
              "8    10.0  4th time we have stayed here. Ther were 9 of u...  Positive\n",
              "9    10.0  12 of us just stayed here on my hen weekend 21...  Positive"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "3EVVPdljMgPS",
        "outputId": "a7d3f053-3c88-4789-f186-0993031a0873"
      },
      "source": [
        "\"\"\"\n",
        "Let's take a quick look at the distribution of sentiments\n",
        "\"\"\"\n",
        "rating_frequency_count = df.Sentiment.value_counts()\n",
        "sns.barplot(x=rating_frequency_count.index, y=rating_frequency_count.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7f70f9afd0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "yQBSi--zMgPU",
        "outputId": "fa79e5b8-33bd-4b11-cc4b-055b55e7b60a"
      },
      "source": [
        "\"\"\"\n",
        "Now let's find out a value for maxlen. For that, we first look at the distribution of review lengths in terms of \n",
        "number of words. A box plot is used to visualize this distribution.\n",
        "\"\"\"\n",
        "\n",
        "re_wordMatcher = re.compile(r'[a-z0-9]+') #Declare regex to extract words\n",
        "numWords = df[\"Review\"].map(lambda x: len(re_wordMatcher.findall(x.lower())))\n",
        "g = sns.boxplot(numWords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um9M2G_1MgPW",
        "outputId": "47fea994-e6ff-417a-e0f1-558695e758b8"
      },
      "source": [
        "\"\"\"\n",
        "The above plot shows that there are few very long reviews (black dots on the right) but most of the reviews are\n",
        "comparatively shorter than around 250 words. Specifically, let's find the 90th quantile of the review length. \n",
        "\"\"\"\n",
        "\n",
        "reviewLen90 = np.quantile(numWords, 0.90)\n",
        "print(\"90th quantile of review length:\", reviewLen90)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90th quantile of review length: 191.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cocVsKqYMgPX"
      },
      "source": [
        "\"\"\"\n",
        "Thus, 90% of reviews are of 191 words or shorter. We'll set maxlen close to this.\n",
        "\"\"\"\n",
        "maxlen = 190"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWHZSO4AMgPY",
        "outputId": "8a60a09a-bf06-4e47-f3f8-8b2df44c2057"
      },
      "source": [
        "\"\"\"\n",
        "Lets's create training and test datasets by keeping ratio between the positive and negative labels same.\n",
        "We use sklearn.model_selection.StratifiedKFold setting number of folds (n_splits) = 5, which splits the data into\n",
        "80% train and 20% test and for 5 folds. But we keep only the first fold for this demo.\n",
        "\"\"\"\n",
        "labels = np.array(df[\"Sentiment\"].map(lambda x: 1. if x == \"Negative\" else 0.))\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "for trn_idx, tst_idx in skf.split(labels.reshape((-1, 1)), labels):\n",
        "    break\n",
        "\n",
        "train_df, test_df = df.iloc[trn_idx], df.iloc[tst_idx]\n",
        "\n",
        "print(\"Shape of train and test dataframes:\", train_df.shape, test_df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of train and test dataframes: (80000, 3) (20000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuH6Y0MwMgPZ"
      },
      "source": [
        "#### Data Processing: Review & Sentiment to Numeric Features & Labels for Model Training & Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kFQgr2jMgPa",
        "outputId": "89fd8431-80f5-4a80-b56f-783f3a61d4f9"
      },
      "source": [
        "#Read FastText En model. If the file wiki.multi.en.vec' does not exist, download it from \n",
        "# https://dl.fbaipublicfiles.com/arrival/vectors/wiki.multi.en.vec\n",
        "!pip install wget\n",
        "import wget\n",
        "word2VecFile = os.path.join(os.curdir, 'wiki.multi.en.vec')\n",
        "\n",
        "if os.path.exists(word2VecFile):\n",
        "    print('Word2Vec file has been found and is being loaded...')\n",
        "else:    \n",
        "    print('Word2Vec file does not exist and needs to be downloaded')\n",
        "    url = 'https://dl.fbaipublicfiles.com/arrival/vectors/wiki.multi.en.vec'\n",
        "    wget.download(url)\n",
        "    print('Downloading from', url)\n",
        "en_model = KeyedVectors.load_word2vec_format('wiki.multi.en.vec')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n",
            "Word2Vec file has been found and is being loaded...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVcwrhPnMgPc",
        "outputId": "560cf48d-5c75-4ede-a1d1-722735bcea10"
      },
      "source": [
        "\"\"\"\n",
        "Now let us create a numpy array containing the word vectors. Later this numpy array will be used for initilaizing \n",
        "the embedding layer in the model.\n",
        "\"\"\"\n",
        "\n",
        "vocab = list(en_model.vocab.keys())\n",
        "print(\"Vocab size in pretrained model:\", len(vocab))\n",
        "\n",
        "# check if the word 'and' is present in the pretrained model\n",
        "assert \"and\" in en_model\n",
        "\n",
        "# check the dimension of the word vectors\n",
        "assert embeddingDim == len(en_model[\"and\"])\n",
        "\n",
        "# initialize a numpy matrix which will store the word vectors\n",
        "# first row is for the padding token\n",
        "pretrained_weights = np.zeros((1+len(vocab), embeddingDim))\n",
        "\n",
        "# tqdm just adds a progress bar\n",
        "for i, token in enumerate(vocab):\n",
        "    pretrained_weights[i, :] = en_model[token]\n",
        "\n",
        "# map tokens in the vocab to ids\n",
        "vocab = dict(zip(vocab, range(1, len(vocab)+1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size in pretrained model: 200000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXY-98CrMgPc"
      },
      "source": [
        "def reviewText2Features(reviewText):\n",
        "    \"\"\"\n",
        "    Function which takes review text (basically a string!) as input and returns a features matrix X of shape\n",
        "    (maxlen, embeddingDim). This is done by splitting the review into words and then representing each word by it's\n",
        "    word vector obtained from the Word2Vec model. Sentences having more than maxlen words are truncated while shorter\n",
        "    ones are zero-padded by pre-adding all zero vectors.\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    \n",
        "    reviewWords = re_wordMatcher.findall(reviewText.lower())\n",
        "    \n",
        "    \"\"\"\n",
        "    Tokenize the review using the word-matching regex and get its word vector from the pretrained Word2Vec model.\n",
        "    Words not found in the Word2Vec model are ignored\n",
        "    \"\"\"\n",
        "    for i, word in enumerate(reviewWords):\n",
        "        if word not in en_model:\n",
        "            continue\n",
        "        if i >= maxlen:\n",
        "            break\n",
        "        # X.append(en_model[word])\n",
        "        X.append(vocab[word])\n",
        "    \n",
        "    \"\"\"\n",
        "    Add zero padding in the begining of the sequence if the number of words is less than maxlen.\n",
        "    \"\"\"\n",
        "    if len(X) < maxlen:\n",
        "        # zero_padding = [[0.]*embeddingDim]*(maxlen - len(X))\n",
        "        zero_padding = [0.]*(maxlen - len(X))\n",
        "        X = zero_padding + X\n",
        "    \n",
        "    return X # np.array(X)\n",
        "        \n",
        "def row2Features(row):\n",
        "    \"\"\"\n",
        "    Function which takes a datafram row as input and produces features and labels.\n",
        "    \n",
        "    Input: row | Type: pandas.core.series.Series\n",
        "    \n",
        "    Output: X, y | Type: X - np.ndarray of shape (maxlen, embeddingDim) & y - int where Positive = 0 & Negative = 1\n",
        "    \"\"\"    \n",
        "    \n",
        "    X = reviewText2Features(row[\"Review\"])\n",
        "    y = 1. if row[\"Sentiment\"] == \"Negative\" else 0.\n",
        "        \n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0k54dpXMgPe",
        "outputId": "d37f0241-e2eb-45ba-96e6-66a3790c8a87"
      },
      "source": [
        "\"\"\"\n",
        "Now apply the above function on a sample row\n",
        "\"\"\"\n",
        "sampleRow = df.iloc[0]\n",
        "reviewWords = re_wordMatcher.findall(sampleRow[\"Review\"].lower())\n",
        "print(\"Review:\", sampleRow[\"Review\"])\n",
        "print(\"Rating:\", sampleRow[\"Rating\"])\n",
        "print(\"Sentiment:\", sampleRow[\"Sentiment\"])\n",
        "print(\"Review words:\", reviewWords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: A dream cottage in a dream village. A very personal service so hard to find these days and by far the most idealistic B & B i have stayed in. Would highly recommend and looking forward to staying again when next in the area. Cornwall.\n",
            "Rating: 10.0\n",
            "Sentiment: Positive\n",
            "Review words: ['a', 'dream', 'cottage', 'in', 'a', 'dream', 'village', 'a', 'very', 'personal', 'service', 'so', 'hard', 'to', 'find', 'these', 'days', 'and', 'by', 'far', 'the', 'most', 'idealistic', 'b', 'b', 'i', 'have', 'stayed', 'in', 'would', 'highly', 'recommend', 'and', 'looking', 'forward', 'to', 'staying', 'again', 'when', 'next', 'in', 'the', 'area', 'cornwall']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQvRGqIeMgPf",
        "outputId": "fa19b520-50c7-4cf5-ecf1-f3799490032a"
      },
      "source": [
        "\"\"\"\n",
        "Give the sample row to the function row2Features\n",
        "\"\"\"\n",
        "X, y = row2Features(sampleRow)\n",
        "print(\"Dimension of X:\", len(X))\n",
        "print(\"Label y:\", y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension of X: 190\n",
            "Label y: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYjRTE-oMgPg"
      },
      "source": [
        "def shuffleArray(X, y):\n",
        "    idx = np.arange(X.shape[0])\n",
        "    np.random.shuffle(idx)\n",
        "    X = X[idx, :]\n",
        "    y = y[idx]\n",
        "    return X, y\n",
        "\n",
        "def generateModelReadyData(data, batchSize = 128, shuffle=False):\n",
        "    \"\"\"\n",
        "    Generator function which generates features and labels in batches\n",
        "    \n",
        "    Input:\n",
        "    data - DataFrame where each row has review and sentiment\n",
        "    batchSize - No. of rows for which features will be created and returned in a batch.\n",
        "    Note: This is useful for running mini-batch Gradient Descent optimization when the dataset is large.\n",
        "    \n",
        "    Output:\n",
        "    X - 3D np.ndarray of shape (batchSize, maxlen, embeddingDim)\n",
        "    y - 1D np. array of shape (batchSize,)        \n",
        "    \"\"\"\n",
        "    \n",
        "    while(True):\n",
        "        X = []\n",
        "        y = []\n",
        "        for _, row in data.iterrows():\n",
        "            \"\"\"Generate features and label for this row\"\"\"\n",
        "            X_, y_ = row2Features(row)\n",
        "\n",
        "            \"\"\"Keep accumulating the row-wise features\"\"\"\n",
        "            X.append(X_)\n",
        "            y.append(y_)   \n",
        "\n",
        "            \"\"\"If number of rows processed is greater than batchSize yield the batch and trim down X & y\n",
        "            Note: This way we avoid running into memory issues by not bloating X and y bigger and bigger\n",
        "            \"\"\"\n",
        "            if len(X) > batchSize:\n",
        "                temp_X, temp_y = np.array(X[:batchSize]), np.array(y[:batchSize])\n",
        "                if shuffle:\n",
        "                    temp_X, temp_y = shuffleArray(temp_X, temp_y)\n",
        "                \n",
        "                X, y = X[batchSize:], y[batchSize:]                    \n",
        "                yield temp_X, temp_y\n",
        "\n",
        "        \"\"\"Yield the remaining few rows when number of rows in data isn't a mutiple of batchSize\"\"\"\n",
        "        if len(X) > 0:\n",
        "            temp_X, temp_y = np.array(X), np.array(y)\n",
        "            if shuffle:\n",
        "                temp_X, temp_y = shuffleArray(temp_X, temp_y)\n",
        "            \n",
        "            yield temp_X, temp_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udBzplxBMgPh",
        "outputId": "87f1b8af-95e8-4e25-bac0-5a727023db08"
      },
      "source": [
        "\"\"\"Let's test the generator function for few batches\"\"\"\n",
        "numBatches = 0\n",
        "for i, (X, y) in enumerate(generateModelReadyData(df, batchSize=128, shuffle=True)):\n",
        "    if numBatches >= 3:\n",
        "        break\n",
        "    \n",
        "    else:\n",
        "        print(\"Batch:\", i)\n",
        "        assert X.shape == (128, maxlen)\n",
        "        assert y.shape == (128,)\n",
        "        print(\"Shape of X & y matches expected values\")\n",
        "    numBatches += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: 0\n",
            "Shape of X & y matches expected values\n",
            "Batch: 1\n",
            "Shape of X & y matches expected values\n",
            "Batch: 2\n",
            "Shape of X & y matches expected values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iudfph_wMgPh"
      },
      "source": [
        "#### Model Training in Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "z2ZY1_OxMgPi",
        "outputId": "86f72919-a18d-4263-ecce-0d805c0d4cd7"
      },
      "source": [
        "\"\"\"\n",
        "Now we will train and evaluate the model. We'll use Pytorch.\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nNow we will train and evaluate the model. We'll use Pytorch.\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9ReXIofMgPi"
      },
      "source": [
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    print(\"cuda available\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALa-sjChMgPi",
        "outputId": "e10ebe26-7a3e-42bd-884f-3b29f69f4303"
      },
      "source": [
        "\"\"\"\n",
        "Set random number seed using torch.manual_seed to make sure the same seed is used\n",
        "by the Pytorch backend and hence ensure repeatable results\n",
        "\"\"\"\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f7f857966b0>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4qJehbktMgPj",
        "outputId": "473f6759-f116-489f-f87e-ad42433102e6"
      },
      "source": [
        "\"\"\"\n",
        "Next, we'll declare the layers of the neural network\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nNext, we'll declare the layers of the neural network\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWj2V_4jMgPj"
      },
      "source": [
        "class SentimentNet(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, pretrained_weights):\n",
        "        super(SentimentNet, self).__init__()\n",
        "        \n",
        "        self.embedding=nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(pretrained_weights))\n",
        "        \n",
        "        \"\"\"\n",
        "        Adding a dropout layer to force some of the feature values to zero.\n",
        "        Note: Dropout is a regularization technique which sets the activation of few randomly chosen neurons of\n",
        "        a hidden layer to zero. It can also be applied to the input layer where some of the input features are set to zero.\n",
        "        For more details refer http://jmlr.org/papers/v15/srivastava14a.html\n",
        "        \"\"\"\n",
        "        self.sentInputDropout = nn.Dropout(0.2)\n",
        "        \n",
        "        \"\"\"\n",
        "        Now let's stack a couple of bidirectional RNNs to process the input sequence and extract features\n",
        "        \"\"\"\n",
        "        self.biLSTM1 = nn.LSTM(embedding_dim, hidden_dim[0], bidirectional=True, batch_first=True)\n",
        "        self.biLSTMDropOut = nn.Dropout(0.2)\n",
        "        self.biLSTM2 = nn.LSTM(2*hidden_dim[0], hidden_dim[1], bidirectional=True, batch_first=True)\n",
        "        \n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "        self.dense1 = nn.Linear(2*hidden_dim[1], 64)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "        \n",
        "        self.outputLayer = nn.Linear(64, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        batch_len = x.shape[0]\n",
        "        out = self.embedding(x)\n",
        "        out = self.sentInputDropout(out)\n",
        "        out, hidden = self.biLSTM1(out)\n",
        "        out = self.biLSTMDropOut(out)\n",
        "        out, hidden = self.biLSTM2(out)\n",
        "        \n",
        "        out = self.dropout1(out)\n",
        "        out = self.dense1(out)\n",
        "        out = self.relu1(out)\n",
        "        out = self.dropout2(out)\n",
        "        \n",
        "        out = self.outputLayer(out)\n",
        "        out = self.sigmoid(out)\n",
        "        out = out.view(batch_len, -1)\n",
        "        out = out[:,-1]\n",
        "        return out    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRo5K_KtMgPk",
        "outputId": "efc4c862-1b0f-495c-d4f7-10b2762287a7"
      },
      "source": [
        "model = SentimentNet(embeddingDim, [256, 128], 1+len(vocab), pretrained_weights)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentNet(\n",
              "  (embedding): Embedding(200001, 300)\n",
              "  (sentInputDropout): Dropout(p=0.2, inplace=False)\n",
              "  (biLSTM1): LSTM(300, 256, batch_first=True, bidirectional=True)\n",
              "  (biLSTMDropOut): Dropout(p=0.2, inplace=False)\n",
              "  (biLSTM2): LSTM(512, 128, batch_first=True, bidirectional=True)\n",
              "  (dropout1): Dropout(p=0.2, inplace=False)\n",
              "  (dense1): Linear(in_features=256, out_features=64, bias=True)\n",
              "  (relu1): ReLU()\n",
              "  (dropout2): Dropout(p=0.2, inplace=False)\n",
              "  (outputLayer): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gym7MkuqMgPl"
      },
      "source": [
        "lr=0.005\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUlTBJ0aMgPu",
        "outputId": "aad29c8f-f479-4696-d499-6e62511dc6d1"
      },
      "source": [
        "epochs = 1\n",
        "counter = 0\n",
        "print_every = 1000\n",
        "clip = 5\n",
        "valid_loss_min = np.Inf\n",
        "\n",
        "model = model.float()\n",
        "model.train()\n",
        "for i in range(epochs):\n",
        "    print(\"Epoch:\", i+1)\n",
        "    #h = model.init_hidden(128)\n",
        "    print(\"Running a pass over the training data...\")\n",
        "    for j, (inputs, labels) in enumerate(generateModelReadyData(train_df, batchSize=128, shuffle=True)):\n",
        "        if j >= np.ceil(train_df.shape[0]/128):\n",
        "            break\n",
        "        \n",
        "    #for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "        #h = tuple([e.data for e in h])\n",
        "        inputs, labels = torch.from_numpy(inputs), torch.from_numpy(labels)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        model.zero_grad()\n",
        "        #output, h = model(inputs, h)\n",
        "        output = model(inputs.long())\n",
        "        #print(output.shape)\n",
        "        #print(output)\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()        \n",
        "        if (j+1) % 100 == 0:\n",
        "            print(\"Batches completed:\", j+1)\n",
        "    \n",
        "    print(\"Batches completed:\", j+1)\n",
        "\n",
        "    #val_h = model.init_hidden(batch_size)\n",
        "    val_losses = []\n",
        "    model.eval()\n",
        "    print(\"Running a pass over the test data...\")\n",
        "    for k, (inp, lab) in enumerate(generateModelReadyData(test_df, batchSize=128, shuffle=False)):\n",
        "        if k >= np.ceil(test_df.shape[0]/128):\n",
        "            break\n",
        "    #for inp, lab in val_loader:\n",
        "        #val_h = tuple([each.data for each in val_h])\n",
        "        inp, lab = torch.from_numpy(inp), torch.from_numpy(lab)\n",
        "        inp, lab = inp.to(device), lab.to(device)\n",
        "        out = model(inp.long())\n",
        "        val_loss = criterion(out.squeeze(), lab.float())\n",
        "        val_losses.append(val_loss.item())\n",
        "        if (k+1) % 100 == 0:\n",
        "            print(\"Batches completed:\", k+1)\n",
        "    \n",
        "    print(\"Batches completed:\", k+1)\n",
        "\n",
        "    model.train()\n",
        "    print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
        "          \"Step: {}...\".format(counter),\n",
        "          \"Loss: {:.6f}...\".format(loss.item()),\n",
        "          \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
        "    if np.mean(val_losses) <= valid_loss_min:\n",
        "        torch.save(model.state_dict(), './state_dict.pt')\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,np.mean(val_losses)))\n",
        "        valid_loss_min = np.mean(val_losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "Running a pass over the training data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbOiB9K3MgPw"
      },
      "source": [
        "\"\"\"\n",
        "Earlier we have seen that the review sentiments are imbalanced with more number of Positive cases than Negative ones.\n",
        "Imbalance datasets make it difficult for the model to learn patterns for the under-represented class.\n",
        "We tackle this problem by introducing class weights during training which are used to assign higher weightage\n",
        "to errors made in predicting the under-represented class.\n",
        "\n",
        "Class weights are computed from inverse of frequency counts as follows.\n",
        "\"\"\"\n",
        "freqCounts = train_df[\"Sentiment\"].value_counts()\n",
        "weightOfPositive = round( (1./freqCounts[\"Positive\"]) / (1./freqCounts[\"Positive\"] + 1./freqCounts[\"Negative\"]), 3)\n",
        "weightOfNegative = round( (1./freqCounts[\"Negative\"]) / (1./freqCounts[\"Positive\"] + 1./freqCounts[\"Negative\"]), 3)\n",
        "print(\"Class weights:\", weightOfPositive, weightOfNegative)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGXoYWs8MgP2"
      },
      "source": [
        "\"\"\"\n",
        "For making predictions, optionally you can use CPU instead of GPU. But for that we need to change the device so that Pytorch can \n",
        "run on CPU. Let us change the device here.\n",
        "\"\"\"\n",
        "# device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqFOHzN6MgP3"
      },
      "source": [
        "#### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_dWMvtvZYak"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbyzZGqaMgP4"
      },
      "source": [
        "\"\"\"\n",
        "At this point we can load a pretrained model which was trained for 5 epochs and make predictions using it.\n",
        "Uncomment and run the below line to load the pretrained model\n",
        "\"\"\"\n",
        "model.load_state_dict(torch.load('./state_dict.pt'))\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGbHhsvpMgP4"
      },
      "source": [
        "test_losses = []\n",
        "num_correct = 0\n",
        "pred_proba = []\n",
        "actual = []\n",
        "\n",
        "model.eval()\n",
        "for j, (X_test, y_test) in enumerate(generateModelReadyData(test_df, batchSize=128)):\n",
        "    if j >= np.ceil(test_df.shape[0]/128):\n",
        "        break\n",
        "    \n",
        "    inputs_test, labels_test = torch.from_numpy(X_test), torch.from_numpy(y_test)\n",
        "    inputs_test, labels_test = inputs_test.to(device), labels_test.to(device)\n",
        "    output_test = model(inputs_test.long())\n",
        "    test_loss = criterion(output_test.squeeze(), labels_test.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "    pred = torch.round(output_test.squeeze())  # Rounds the output to 0/1\n",
        "    correct_tensor = pred.eq(labels_test.float().view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "    pred_proba.extend(output_test.cpu().squeeze().detach().numpy())\n",
        "    actual.extend(y_test)\n",
        "    \n",
        "    if (j+1) % 100 == 0:\n",
        "        print(\"Batches completed:\", j+1)\n",
        "\n",
        "print(\"Batches completed:\", j+1)\n",
        "\n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "test_acc = num_correct/len(test_df)\n",
        "print(\"Test accuracy: {:.3f}%\".format(test_acc*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SovVGfb4MgQB"
      },
      "source": [
        "\"\"\"\n",
        "Evaluate using Area Under Reciever Operating Charecteristic curve\n",
        "Reference on AUC-ROC: https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5\n",
        "\"\"\"\n",
        "print(\"Area under ROC:\", roc_auc_score(actual, pred_proba))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oen2zsbtMgQC"
      },
      "source": [
        "\"\"\"\n",
        "Let's plot the ROC curve.\n",
        "First, we will compute False Positive Rate (FPR) & True Postive Rate (TPR) for different values of threshold and\n",
        "find the area under the curve.\n",
        "Note: Positive here indicates class label = 1 which is Negative sentiment in our case\n",
        "      Negative indicates class label = 0 which is Positive sentiment in our case\n",
        "\"\"\"\n",
        "fpr, tpr, thresholds = roc_curve(actual, pred_proba) \n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange',\n",
        "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic example')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH5K-myYMgQD"
      },
      "source": [
        "\"\"\"\n",
        "Let's convert predicted probabilites to predicted sentiments using a threshold=0.10\n",
        "and compute the confusion matrix\n",
        "\"\"\"\n",
        "\n",
        "predicted = pd.Series([\"Negative\" if p>=0.10 else \"Positive\" for p in pred_proba], name=\"Predicted\")\n",
        "actual = pd.Series(test_df[\"Sentiment\"], name=\"Actual\")\n",
        "confusion_matrix = pd.crosstab(actual, predicted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k86rLlE3MgQE"
      },
      "source": [
        "\"\"\"Plot the confusion matrix\"\"\"\n",
        "\n",
        "ax= plt.subplot()\n",
        "g = sns.heatmap(confusion_matrix.as_matrix(), annot=True, ax = ax, fmt=\"d\", cmap=\"YlGnBu\")\n",
        "g.set_xlabel('Predicted')\n",
        "g.set_ylabel('Actual')\n",
        "g.set_title('Confusion Matrix')\n",
        "g.xaxis.set_ticklabels(['Negative', 'Positive'])\n",
        "g.yaxis.set_ticklabels(['Negative', 'Positive'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4uTQKFlMgQE"
      },
      "source": [
        "#### Sentiment Prediction for new reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSomly6HMgQG"
      },
      "source": [
        "\"\"\"\n",
        "Let us now see how to predict Sentiment of a review. For this we'll use the function\n",
        "reviewText2Features which converts a review into a feature matrix X. However, X is 2D tensor while the model's network\n",
        "expects a 3D tensor of dimensions (batch_size, maxlen, embeddingDim). Hence, for a single review we reshape the output\n",
        "of reviewText2Features to dimensions (1, maxlen, embeddingDim). This 3D matrix is given to the model which outputs predicted\n",
        "probability. This in turn is converted to Sentiment applying the above threshold.\n",
        "\n",
        "The below function wraps in all these logic.\n",
        "\"\"\"\n",
        "\n",
        "def predictSentiment(reviewText):\n",
        "    X = reviewText2Features(reviewText)\n",
        "    X = np.array(X).reshape((1, -1))\n",
        "    X = torch.from_numpy(X)\n",
        "    X = X.to(device)\n",
        "    model.eval()\n",
        "    pred_proba = model(X.long())\n",
        "    pred_proba = pred_proba.cpu().squeeze().detach().numpy()\n",
        "    if pred_proba >= 0.10:\n",
        "        return \"Negative\", pred_proba\n",
        "    else:\n",
        "        return \"Positive\", pred_proba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJZXnRPwMgQI"
      },
      "source": [
        "\"\"\"\n",
        "Now test the above function with few positive and negative reviews from test_df\n",
        "\"\"\"\n",
        "\n",
        "pos_reviews = list(test_df[\"Review\"].loc[test_df[\"Sentiment\"] == \"Positive\"].iloc[:5])\n",
        "neg_reviews = list(test_df[\"Review\"].loc[test_df[\"Sentiment\"] == \"Negative\"].iloc[:5])\n",
        "\n",
        "for reviewText, actualSentiment in  zip(pos_reviews + neg_reviews, [\"Positive\"]*5+[\"Negative\"]*5):\n",
        "    sentiment, probability = predictSentiment(reviewText)\n",
        "    \"\"\"\n",
        "    Since, the model always predicts probability of being Negative, we compute (1-probability) as \n",
        "    probability when predicted sentiment is Positive\n",
        "    \"\"\"\n",
        "    if sentiment == \"Positive\":\n",
        "        probability = 1 - probability\n",
        "    \n",
        "    probability = np.round(probability, 4)\n",
        "    print(\"Review: \", reviewText)\n",
        "    print(\"Actual Sentiment:\", actualSentiment)\n",
        "    print(\"Predicted Sentiment: \", sentiment)\n",
        "    print(\"x---------------------------------------------------------------------------------------------------x\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}